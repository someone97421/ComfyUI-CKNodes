import torch
import numpy as np
from PIL import Image
import io
import base64
import os
import json

# å°è¯•å¯¼å…¥openaiåº“ï¼Œå¦‚æœæ²¡æœ‰å®‰è£…åˆ™æŠ¥é”™æç¤º
try:
    from openai import OpenAI
except ImportError:
    print("\033[31m[ComfyUI OpenAI Node] Error: 'openai' library not found. Please run: pip install openai\033[0m")

class SimpleOpenAI_LLM:
    def __init__(self):
        pass
    
    @classmethod
    def INPUT_TYPES(s):
        return {
            "required": {
                "api_url": ("STRING", {
                    "default": "https://api.openai.com/v1", 
                    "multiline": False,
                    "tooltip": "APIæ¥å…¥ç‚¹ (Base URL). æœ¬åœ°æ¨¡å‹å¯ç”¨ http://localhost:11434/v1"
                }),
                "api_key": ("STRING", {
                    "default": "sk-...", 
                    "multiline": False,
                    "tooltip": "ä½ çš„ API Key. æœ¬åœ°æ¨¡å‹éšä¾¿å¡«å³å¯"
                }),
                "model_name": ("STRING", {
                    "default": "gpt-4o", 
                    "multiline": False,
                    "tooltip": "æ¨¡å‹åç§°, å¦‚ gpt-4o, gpt-4o-mini, llama3, deepseek-chat"
                }),
                "system_prompt": ("STRING", {
                    "default": "You are a helpful assistant.", 
                    "multiline": True,
                    "dynamicPrompts": True
                }),
                "user_prompt": ("STRING", {
                    "default": "Describe this image in detail.", 
                    "multiline": True,
                    "dynamicPrompts": True
                }),
                "temperature": ("FLOAT", {"default": 0.7, "min": 0.0, "max": 2.0, "step": 0.1}),
                "max_tokens": ("INT", {"default": 2048, "min": 1, "max": 128000}),
                "seed": ("INT", {"default": 0, "min": 0, "max": 0xffffffffffffffff}),
            },
            "optional": {
                "images": ("IMAGE", ), # æ”¯æŒå›¾ç‰‡æ‰¹æ¬¡ï¼ˆè§†é¢‘å¸§ï¼‰
            }
        }

    RETURN_TYPES = ("STRING",)
    RETURN_NAMES = ("response_text",)
    FUNCTION = "generate_completion"
    CATEGORY = "ğŸ‘»CKNodes"

    def tensor_to_base64(self, image_tensor):
        """å°†ComfyUIçš„Tensorå›¾ç‰‡è½¬æ¢ä¸ºBase64å­—ç¬¦ä¸²"""
        # Tensorå½¢çŠ¶: [Batch, Height, Width, Channel] -> è¿™é‡Œçš„è¾“å…¥æ˜¯å•å¼  [H, W, C]
        i = 255. * image_tensor.cpu().numpy()
        img = Image.fromarray(np.clip(i, 0, 255).astype(np.uint8))
        
        buffered = io.BytesIO()
        # é»˜è®¤ä¿å­˜ä¸ºJPEGä»¥èŠ‚çœTokenï¼Œè´¨é‡è®¾ä¸º85
        img.save(buffered, format="JPEG", quality=85)
        img_str = base64.b64encode(buffered.getvalue()).decode("utf-8")
        return f"data:image/jpeg;base64,{img_str}"

def generate_completion(self, api_url, api_key, model_name, system_prompt, user_prompt, temperature, max_tokens, seed, images=None):
        
        # åˆå§‹åŒ–å®¢æˆ·ç«¯
        client = OpenAI(
            api_key=api_key,
            base_url=api_url
        )

        # æ„å»ºæ¶ˆæ¯å†…å®¹
        content_list = [{"type": "text", "text": user_prompt}]

        # å¤„ç†å›¾ç‰‡è¾“å…¥ (æ”¯æŒ Batch/Video)
        if images is not None:
            batch_size = images.shape[0]
            for i in range(batch_size):
                image_data = self.tensor_to_base64(images[i])
                content_list.append({
                    "type": "image_url",
                    "image_url": {
                        "url": image_data,
                        "detail": "auto" 
                    }
                })

        messages = [
            {"role": "system", "content": system_prompt},
            {"role": "user", "content": content_list}
        ]

        try:
            response = client.chat.completions.create(
                model=model_name,
                messages=messages,
                temperature=temperature,
                max_tokens=max_tokens,
                seed=seed
            )
            
            # --- ä¿®å¤æ ¸å¿ƒï¼šå…¼å®¹æ€§å¤„ç† ---
            
            # æƒ…å†µ1: å¦‚æœè¿”å›çš„æ˜¯å­—ç¬¦ä¸²ï¼ˆRaw JSON æˆ– ç›´æ¥æ–‡æœ¬ï¼‰
            if isinstance(response, str):
                # å°è¯•è§£æ JSON
                try:
                    response = json.loads(response)
                except:
                    # å¦‚æœæ— æ³•è§£æJSONï¼Œå‡è®¾å®ƒå°±æ˜¯æœ€ç»ˆçš„æ–‡æœ¬ç»“æœï¼ˆæŸäº›éæ ‡APIçš„è¡Œä¸ºï¼‰
                    return (response,)

            # æƒ…å†µ2: å¦‚æœæ˜¯å­—å…¸ (Dict)ï¼Œé€šå¸¸å‘ç”Ÿåœ¨ä½¿ç”¨æ—§ç‰ˆåº“æˆ–ä»£ç†æ—¶
            if isinstance(response, dict):
                # ä½¿ç”¨å­—å…¸æ–¹å¼å–å€¼ ['choices']
                if 'choices' in response and len(response['choices']) > 0:
                    choice = response['choices'][0]
                    # choice æœ¬èº«ä¹Ÿå¯èƒ½æ˜¯å­—å…¸æˆ–å¯¹è±¡
                    if isinstance(choice, dict):
                        result = choice.get('message', {}).get('content', '')
                    else:
                        result = choice.message.content
                    return (result,)
                else:
                    return (f"API Error: Invalid dict response {response}",)

            # æƒ…å†µ3: æ ‡å‡† OpenAI å¯¹è±¡ (Object)
            if hasattr(response, 'choices') and len(response.choices) > 0:
                result = response.choices[0].message.content
                return (result,)
            
            # æœªçŸ¥æƒ…å†µ
            return (f"API Error: Unknown response format: {type(response)}",)
            
        except Exception as e:
            error_msg = f"API Error: {str(e)}"
            print(f"\033[31m{error_msg}\033[0m")
            return (error_msg,)
# èŠ‚ç‚¹æ˜ å°„
NODE_CLASS_MAPPINGS = {
    "SimpleOpenAI_LLM": SimpleOpenAI_LLM
}

NODE_DISPLAY_NAME_MAPPINGS = {
    "SimpleOpenAI_LLM": "ğŸ‘»ç®€å•LLMåŠ©æ‰‹-APIğŸ‘»"

}
